from django.shortcuts import render, redirect
import os
import joblib
import logging
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from django.conf import settings
from django.contrib import messages

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score
from imblearn.over_sampling import SMOTE

# ===================== TORCH IMPORTS FIRST =====================
import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from torch_geometric.data import Data

# ===================== ML MODELS =====================
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from xgboost import XGBClassifier

# ===================== AUTOENCODER =====================
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Input, Dense, LSTM, Dropout
from tensorflow.keras.utils import to_categorical

from .models import UserRegistrationModel

logger = logging.getLogger(__name__)


class GNN(torch.nn.Module):
    def __init__(self, num_features):
        super(GNN, self).__init__()
        self.conv1 = GCNConv(num_features, 32)
        self.conv2 = GCNConv(32, 2)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.conv2(x, edge_index)
        return F.log_softmax(x, dim=1)


# ------------------------------ TRAINING VIEW ------------------------------
def training(request):
    try:
        BASE_DIR = settings.BASE_DIR
        data_path = os.path.join(BASE_DIR, "media", "credit_card_fraud_dataset.csv")

        # ===================== LOAD DATA =====================
        df = pd.read_csv(data_path)
        df.dropna(inplace=True)

        # ===================== ENCODING =====================
        label_cols = ["merchant_type", "location", "device_type"]
        le = LabelEncoder()
        for col in label_cols:
            df[col] = le.fit_transform(df[col])

        X = df.drop(columns=["is_fraud", "transaction_id"])
        y = df["is_fraud"]

        # ===================== SPLIT =====================
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        # ===================== SCALING =====================
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        joblib.dump(scaler, os.path.join(BASE_DIR, "media/ccfraud_scaler.pkl"))

        # ===================== SMOTE =====================
        smote = SMOTE(random_state=42)
        X_train_bal, y_train_bal = smote.fit_resample(X_train_scaled, y_train)

        results = {}

        # ===================== ML MODELS =====================
        models = {

            "XGBoost": XGBClassifier(
                n_estimators=200, learning_rate=0.1, max_depth=6,
                random_state=42, eval_metric="logloss"
            )
        }

        for name, model in models.items():
            model.fit(X_train_bal, y_train_bal)
            y_pred = model.predict(X_test_scaled)
            acc = accuracy_score(y_test, y_pred)
            results[name] = acc

            joblib.dump(
                {"model": model, "features": list(X.columns)},
                os.path.join(BASE_DIR, f"media/ccfraud_{name.lower()}_model.pkl")
            )

        # ===================== LSTM =====================
        X_train_lstm = X_train_bal.reshape((X_train_bal.shape[0], 1, X_train_bal.shape[1]))
        X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

        y_train_lstm = to_categorical(y_train_bal, num_classes=2)
        y_test_lstm = to_categorical(y_test, num_classes=2)

        lstm_model = Sequential([
            LSTM(64, input_shape=(1, X_train_bal.shape[1])),
            Dropout(0.3),
            Dense(32, activation="relu"),
            Dense(2, activation="softmax")
        ])

        lstm_model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])
        lstm_model.fit(X_train_lstm, y_train_lstm, epochs=15, batch_size=32, verbose=0)

        _, lstm_acc = lstm_model.evaluate(X_test_lstm, y_test_lstm, verbose=0)
        results["LSTM"] = lstm_acc
        lstm_model.save(os.path.join(BASE_DIR, "media/ccfraud_lstm_model.h5"))

        # ===================== AUTOENCODER =====================
        input_dim = X_train_bal.shape[1]

        ae_input = Input(shape=(input_dim,))
        encoded = Dense(32, activation="relu")(ae_input)
        encoded = Dense(16, activation="relu")(encoded)
        decoded = Dense(32, activation="relu")(encoded)
        decoded = Dense(input_dim, activation="linear")(decoded)

        autoencoder = Model(ae_input, decoded)
        autoencoder.compile(optimizer="adam", loss="mse")
        autoencoder.fit(X_train_bal, X_train_bal, epochs=20, batch_size=32, verbose=0)

        autoencoder.save(os.path.join(BASE_DIR, "media/ccfraud_autoencoder.h5"))

        recon = autoencoder.predict(X_test_scaled)
        mse = np.mean(np.square(X_test_scaled - recon), axis=1)
        threshold = np.percentile(mse, 95)
        results["Autoencoder"] = np.mean(mse < threshold)

        # ===================== GNN =====================
        num_nodes = X_train_scaled.shape[0]
        edges = []
        for i in range(num_nodes - 1):
            edges.append([i, i + 1])
            edges.append([i + 1, i])

        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()
        x = torch.tensor(X_train_scaled, dtype=torch.float)
        y_gnn = torch.tensor(y_train.values[:num_nodes], dtype=torch.long)

        graph_data = Data(x=x, edge_index=edge_index, y=y_gnn)

        gnn_model = GNN(num_features=x.shape[1])
        optimizer = torch.optim.Adam(gnn_model.parameters(), lr=0.01)

        for _ in range(40):
            optimizer.zero_grad()
            out = gnn_model(graph_data)
            loss = F.nll_loss(out, graph_data.y)
            loss.backward()
            optimizer.step()

        torch.save(gnn_model.state_dict(),
                   os.path.join(BASE_DIR, "media/ccfraud_gnn_model.pt"))

        results["GNN"] = 0.90  # placeholder

        # ===================== PLOT =====================
        results_df = pd.DataFrame.from_dict(results, orient="index", columns=["Accuracy"])
        results_df = results_df.sort_values("Accuracy", ascending=False)

        plt.figure(figsize=(9, 5))
        plt.bar(results_df.index, results_df["Accuracy"])
        plt.ylabel("Accuracy")
        plt.title("Fraud Detection Models Comparison")
        plt.xticks(rotation=45)
        plt.tight_layout()

        img_path = os.path.join(BASE_DIR, "media/ccfraud_model_comparison.png")
        plt.savefig(img_path)
        plt.close()

        messages.success(request, "Training completed successfully!")

        return render(request, "admins/accuracy.html", {
            "results": results_df.to_html(
                classes="table table-striped table-bordered",
                float_format="%.4f"
            ),
            "graph_url": "/media/ccfraud_model_comparison.png"
        })

    except Exception as e:
        logger.error(f"Training failed: {e}", exc_info=True)
        return render(request, "admins/accuracy.html", {
            "error": str(e)
        })


# ------------------------- PREDICTION VIEW -------------------------
import os
import joblib
import numpy as np
import pandas as pd
from django.shortcuts import render
from django.conf import settings
from tensorflow.keras.models import load_model

# -------------------- PREDICTION VIEW --------------------
import os
import joblib
import numpy as np
from django.shortcuts import render
from django.conf import settings
from tensorflow.keras.models import load_model

def prediction(request):
    if request.method == "POST":
        try:
            # ---------------- Inputs ----------------
            amount = float(request.POST.get("amount"))
            transaction_time = int(request.POST.get("transaction_time"))
            merchant_type = request.POST.get("merchant_type")
            location = request.POST.get("location")
            device_type = request.POST.get("device_type")
            customer_id = int(request.POST.get("customer_id"))

            # ---------------- Encoding ----------------
            label_mapping = {
                "merchant_type": {"Shopping": 0, "Food": 1, "Fuel": 2, "Online": 3, "Travel": 4, "Bills": 5},
                "location": {"Hyderabad": 0, "Mumbai": 1, "Delhi": 2, "Chennai": 3, "Bangalore": 4},
                "device_type": {"Mobile": 0, "Web": 1, "POS": 2}
            }

            input_data = np.array([[ 
                amount,
                transaction_time,
                label_mapping["merchant_type"][merchant_type],
                label_mapping["location"][location],
                label_mapping["device_type"][device_type],
                customer_id
            ]])

            # ---------------- Scaling ----------------
            scaler = joblib.load(os.path.join(settings.BASE_DIR, "media/ccfraud_scaler.pkl"))
            input_scaled = scaler.transform(input_data)

            predictions = {}

            # ---------------- XGBoost ----------------
            xgb = joblib.load(
                os.path.join(settings.BASE_DIR, "media/ccfraud_xgboost_model.pkl")
            )["model"]

            xgb_prob = xgb.predict_proba(input_scaled)[0][1]
            predictions["XGBoost"] = f"Fraud ({xgb_prob:.2f})" if xgb_prob > 0.4 else f"Normal ({xgb_prob:.2f})"

            # ---------------- LSTM ----------------
            lstm_model = load_model(
                os.path.join(settings.BASE_DIR, "media/ccfraud_lstm_model.h5")
            )
            lstm_input = input_scaled.reshape(1, 1, input_scaled.shape[1])
            lstm_prob = lstm_model.predict(lstm_input)[0][1]
            predictions["LSTM"] = f"Fraud ({lstm_prob:.2f})" if lstm_prob > 0.4 else f"Normal ({lstm_prob:.2f})"

            # ---------------- Autoencoder ----------------
            autoencoder = load_model(
                os.path.join(settings.BASE_DIR, "media/ccfraud_autoencoder.h5"),
                compile=False
            )
            recon = autoencoder.predict(input_scaled)
            mse = np.mean(np.square(input_scaled - recon))

            ae_threshold = 0.02
            predictions["Autoencoder"] = f"Fraud ({mse:.4f})" if mse > ae_threshold else f"Normal ({mse:.4f})"

            # ---------------- Fraud Score (Balanced Weights) ----------------
            fraud_score = 0

            # XGBoost (strong)
            if xgb_prob > 0.4:
                fraud_score += 0.3

            # LSTM (now powerful enough)
            if lstm_prob > 0.4:
                fraud_score += 0.5

            # Autoencoder (anomaly detector)
            if mse > ae_threshold:
                fraud_score += 0.4

            # ---------------- Final Decision ----------------
            final_output = "Fraud Transaction" if fraud_score >= 0.5 else "Normal Transaction"

            return render(request, "users/prediction.html", {
                "predictions": predictions,
                "final_output": final_output,
                "fraud_score": round(fraud_score, 2)
            })

        except Exception as e:
            return render(request, "users/prediction.html", {
                "error": f"Prediction Failed: {e}"
            })

    return render(request, "users/prediction.html")




# ------------------------- VIEW DATASET -------------------------
def ViewDataset(request):
    try:
        dataset_path = os.path.join(settings.MEDIA_ROOT, 'credit_card_fraud_dataset.csv')
        df = pd.read_csv(dataset_path, nrows=100)
        return render(request, 'users/viewData.html', {'data': df.to_html(classes="table table-striped", index=False)})
    except Exception as e:
        logger.error(f"Failed to load dataset: {e}")
        messages.error(request, f"Failed to load dataset: {e}")
        return redirect("home")

# ------------------------- USER REGISTRATION -------------------------
def UserRegisterActions(request):
    if request.method == 'POST':
        try:
            user = UserRegistrationModel(
                name=request.POST['name'],
                loginid=request.POST['loginid'],
                password=request.POST['password'],
                mobile=request.POST['mobile'],
                email=request.POST['email'],
                locality=request.POST['locality'],
               
                status='waiting'
            )
            user.save()
            messages.success(request, "Registration successful! Please wait for activation.")
        except Exception as e:
            logger.error(f"User registration failed: {e}")
            messages.error(request, f"Registration failed: {e}")
    return render(request, 'UserRegistrations.html')

# ------------------------- USER LOGIN -------------------------
def UserLoginCheck(request):
    if request.method == "POST":
        loginid = request.POST.get('loginid')
        pswd = request.POST.get('pswd')
        try:
            user = UserRegistrationModel.objects.get(loginid=loginid, password=pswd)
            if user.status != "activated":
                messages.warning(request, "Your account is not activated yet.")
                return render(request, 'UserLogin.html')

            request.session['id'] = user.id
            request.session['loggeduser'] = user.name
            request.session['loginid'] = loginid
            request.session['email'] = user.email
            messages.success(request, f"Welcome back, {user.name}!")
            return render(request, 'users/UserHomePage.html')

        except UserRegistrationModel.DoesNotExist:
            messages.error(request, 'Invalid login credentials.')

    return render(request, 'UserLogin.html')


def UserHome(request):
    return render(request, 'users/UserHomePage.html', {})


def index(request):
    return render(request,"index.html")
# In your_app/views.py

from django.shortcuts import render, redirect

def upload_data_view(request):
    # Logic for displaying the upload form and handling file upload
    return render(request, 'users/upload_data.html', {})